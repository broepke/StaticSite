Title: The Magic of Principal Component Analysis through Image Compression
Date: 2022-02-20
Modified: 2022-02-20
Status: draft
Tags: datascience, python, sklearn
Slug: pcavisualized
Authors: Brian Roepke
Summary: Utilizing Images to Beautifully Demonstrate PCA
Header_Cover: images/covers/less.jpg
Og_Image: images/covers/less.jpg
Twitter_Image: images/covers/less.jpg

## What is PCA?

Principal Component Analysis or PCA is a *dimensionality reduction technique* for data sets with many features or dimensions.  It uses linear algebra to determine the most important features of a dataset.  After these features have been identified, you can use only these features to train a machine learning model and improve performance without sacrificing accuracy.

PCA finds the axis with the maximum variance and projects the points onto this axis.  PCA uses a concept from Linear Algebra known as Eigenvectors and Eigenvalues.  There is a post on **Stack Exchange** which beautifully explains it.


## Conclusion

*If you liked what you read, [subscribe to my newsletter](https://campaign.dataknowsall.com/subscribe) and you will get my cheat sheet on Python, Machine Learning (ML), Natural Language Processing (NLP), SQL, and more. You will receive an email each time a new article is posted.*
## References

Photo by <a href="https://unsplash.com/@k8_iv?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">K8</a> on <a href="https://unsplash.com/s/photos/less-is-more?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>

search - less is more